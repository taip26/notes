#  

Speaker: Michelle Zhao

Human feedback underpins autonomous paradigms. Robots rely heavily on human supervision and correction, but this may not improve the policy for sufficient generalization. The solution is a collaborative approach where the robots takes a proactive approach to learning, letting the human know when it doesn't know how to do certain actions during data collection. The goal is to learn the robot policy, where the robot learns to take actions like the expert human. All the corrections get added to the dataset, and the robot learns interatively. There are two approaches for human intervention, where the human chooses to intervene or the robot asks for intervention. A good confidence measure must be determined such that the robot can ask for help effectively. Adaptive uncertainty via Online Conformal Prediction is where human feedback is given intermittedly and the time interval is only updated if the expert feedback is observed. We can combine human and robot-gated feedback to calibrate the uncertainty signal. During an experiment, it finds that the robot asks for more help when misaligned from the expert. ConformalDAgger captures longer continuous segments than EnsembleDAgger. ConformalDAgger increases requests only when needed. Assistive policies for shared autonomy is used to account for low dimensional inputs to robot's high dimensional output. For user-calibrated assessment, we need uncertainty estimation and user-calibration. Each user gives a desired high dim result as well as their low dim input to achieve that result, where it is shown that each user has a lot of different approaches to the same result. Uncalibrated intervals fail to reflect uncertainty on OOD inputs. Uncertainty calibation via Conformal Prediction is used. Learning on the job encounters different types of interactions. Modeling interaction costs is important, since it takes more effort than corrections. Iterative planning allows adaptation to teaching failures. How to assess capability? Uncertainty quantification from interactive sources allows different avenues for collaborative human-robot interactions. Longitudinal co-learning is where users learn how to interact with robots over time.
