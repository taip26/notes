Jimmy Leng

Use quantum computing in machine learning
GD with superposition (shrodinger's GD)
 - simulate path 1 and 2, so 50% chance of success rate instead of 0 with bad initialization

Path integration of all GD trajectories.

This seminar proposes Quantum Hamiltonian Descent. For convex optimization, QHD is a quantum 0th order method, so no gradients are involved. Additionally, QHD can be started from any inital state, but time discretion must be noted. For structed non-convex optimization, QHD theoretically gains a large boost in runtime compared to classical algorithms, going from exponential or super-polynomial to polynomial for "natural" or "contrived" optimizations respectively.

To go from QHD to software, a QHD-based-OPTimizer (QHDOPT) is sed for nonlinear optimization. It uses a Hamiltonian embedding to map algorithms to hardware, which sees up to a tenfold speedup in Time-to-Solution testing. This has various real-world applications that span from energy and power systems to design automation.

In QHD + QHDOPT, it is a static workflow with no interaction with problem input. The classical system sends an input to the quantum computing engine, there is feedback to the classical system, and this process continues iteratively until the optimal solution is found. 

2 directions to take this
 - Quantum for multi-objective optimization
 - Hardware-efficient Deployment

Summary:
This seminar explores the integration of quantum computing with machine learning, focusing on optimization through a framework called Quantum Hamiltonian Descent (QHD). The central motivation is that classical gradient descent (GD) methods are highly sensitive to initialization, often failing in non-convex landscapes. By leveraging quantum superposition, which the speaker  describes as a “Schrödinger’s GD,” multiple optimization paths can be explored simultaneously. Rather than committing to a single trajectory that may fail in classical GD, the quantum system effectively simulates multiple paths at once, increasing the probability of reaching a successful solution. This idea extends to path integration over all gradient descent trajectories, enabling a fundamentally different search strategy compared to classical methods. The seminar introduces QHD as a quantum zeroth-order optimization method, meaning it does not require gradient information. For convex optimization, QHD can begin from any initial state, though careful time discretization is required. More notably, for structured non-convex optimization problems, QHD theoretically offers significant runtime improvements, reducing exponential or super-polynomial complexity to polynomial time for certain natural or contrived problem classes. This suggests strong theoretical advantages over classical optimization algorithms in specific regimes. To bridge theory and practice, the speaker presents QHDOPT, a QHD-based optimizer designed for nonlinear optimization. QHDOPT employs Hamiltonian embedding to map optimization algorithms directly onto quantum hardware. In Time-to-Solution benchmarking, this approach demonstrates up to a tenfold speedup. The workflow is hybrid and iterative: a classical system submits problem inputs to a quantum engine, receives feedback, and continues iterating until convergence. Applications span several domains, including energy and power systems and design automation Future research directions include extending QHD methods to multi-objective optimization and improving hardware-efficient deployment. Overall, the seminar highlights how quantum dynamics can reshape optimization in machine learning, offering both theoretical speedups and early empirical performance gains through hybrid classical-quantum workflows.
I strongly recommend Jimmy Leng as a faculty member in the Virginia Tech CS department. He demonstrates an exceptional ability to communicate complex ideas clearly, particularly when presenting mathematically rigorous material. Rather than becoming lost in dense proofs, he emphasizes the key insights and conceptual breakthroughs that drive the results, making advanced topics accessible without sacrificing depth. I would also confidently choose him as a research advisor, as he shows a breadth and depth of knowledge in many subjects including quantum computingand machine learning. He presents the material in a way that is approachable for students entering the field, which is a quality trait for a research advisor. Given the growing importance of quantum research and the need to expand its presence within the CS department, Leng would be a valuable addition who strengthens both research capacity and instructional excellence at Virginia Tech.

 
